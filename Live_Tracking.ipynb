{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from ultralytics import YOLO  \n",
    "from sort import *   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gpt Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tcp @ 0x3aeac800] Connection to tcp://192.168.1.100:8080 failed: Connection timed out\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sort import Sort  # SORT tracker\n",
    "from ultralytics import YOLO  # YOLOv8 object detection\n",
    "\n",
    "# Load the reference histogram for traffic light detection\n",
    "with open('./Histogram/modelTown_histogram.pkl', 'rb') as f:\n",
    "    ref_hist = pickle.load(f)\n",
    "\n",
    "# Initialize YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Initialize SORT tracker\n",
    "tracker = Sort()\n",
    "\n",
    "# Define region of interest for traffic light detection\n",
    "bbox = (0.485879, 0.577487, 0.016630, 0.051067)  # Adjust as needed\n",
    "\n",
    "# Define threshold for histogram similarity (adjustable based on performance)\n",
    "HIST_THRESHOLD = 0.8\n",
    "\n",
    "# Define lines for violation detection\n",
    "upper_line = 300  # Vehicles should not cross this when the light is red\n",
    "lower_line = 350  # Vehicles start moving from here\n",
    "\n",
    "# Capture video from mobile camera\n",
    "cap = cv2.VideoCapture(\"http://192.168.1.100:8080/video\")\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for histogram calculation\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    roi = gray_frame[int(bbox[1]):int(bbox[1] + bbox[3]), int(bbox[0]):int(bbox[0] + bbox[2])]\n",
    "\n",
    "    \n",
    "    # Compute histogram and compare with reference\n",
    "    hist = cv2.calcHist([roi], [0], None, [256], [0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    similarity = cv2.compareHist(ref_hist, hist, cv2.HISTCMP_CORREL)\n",
    "    \n",
    "    # Detect objects using YOLOv8\n",
    "    detections = model(frame)\n",
    "    dets = []\n",
    "    for det in detections.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "        if int(cls) == 2 and conf > 0.5:  # Class 2 is 'car'\n",
    "            dets.append([x1, y1, x2, y2, conf])\n",
    "    \n",
    "    # Update tracker\n",
    "    trackers = tracker.update(np.array(dets))\n",
    "    \n",
    "    # Check for violations if the traffic light is red\n",
    "    if similarity > HIST_THRESHOLD:\n",
    "        for track in trackers:\n",
    "            x1, y1, x2, y2, track_id = track.astype(int)\n",
    "            centroid_x, centroid_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            \n",
    "            if centroid_y < upper_line and centroid_y > lower_line:\n",
    "                # Mark violation (Car crossed the red signal)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red box\n",
    "                cv2.arrowedLine(frame, (centroid_x, centroid_y - 20), (centroid_x, centroid_y - 50), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"Violation: Car {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            else:\n",
    "                # Regular tracking\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n",
    "                cv2.putText(frame, f\"Car {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display output\n",
    "    cv2.imshow(\"Real-Time Traffic Violation Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSeek Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sort import Sort  # Make sure SORT is installed\n",
    "\n",
    "# ------------------ Histogram Functions ------------------\n",
    "def load_histogram(file_path):\n",
    "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def calculate_histogram(frame, bbox):\n",
    "    \"\"\"Calculate color histogram for specified region.\"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    x_center, y_center, box_w, box_h = bbox\n",
    "    \n",
    "    # Calculate ROI coordinates\n",
    "    x1 = max(0, int((x_center - box_w/2) * width))\n",
    "    y1 = max(0, int((y_center - box_h/2) * height))\n",
    "    x2 = min(width, int((x_center + box_w/2) * width))\n",
    "    y2 = min(height, int((y_center + box_h/2) * height))\n",
    "    \n",
    "    # Extract ROI and safety checks\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return np.zeros((8*8*8,), dtype=np.float32)  # Match reference histogram size\n",
    "    \n",
    "    # Convert to HSV color space\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate 3D histogram (8 bins per channel)\n",
    "    hist = cv2.calcHist([hsv_roi], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "def compare_histograms(hist1, hist2):\n",
    "    \"\"\"Compare histograms using correlation coefficient.\"\"\"\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "# ------------------ Tracking Functions ------------------\n",
    "def is_within_path(x, y, path_bbox, frame_shape):\n",
    "    \"\"\"Check if point is within violation zone.\"\"\"\n",
    "    h, w = frame_shape[:2]\n",
    "    px, py, pw, ph = path_bbox\n",
    "    return (px - pw/2)*w <= x <= (px + pw/2)*w and \\\n",
    "           (py - ph/2)*h <= y <= (py + ph/2)*h\n",
    "\n",
    "def point_side(point, line_start, line_end):\n",
    "    \"\"\"Determine which side of the line the point is on.\"\"\"\n",
    "    return (point[0] - line_start[0]) * (line_end[1] - line_start[1]) - \\\n",
    "           (point[1] - line_start[1]) * (line_end[0] - line_start[0])\n",
    "\n",
    "# ------------------ Main Configuration ------------------\n",
    "# Update these values according to your setup\n",
    "CONFIG = {\n",
    "    \"histogram_file\": \"./Histogram/modelTown_histogram.pkl\",\n",
    "    \"signal_bbox\": (0.485879, 0.577487, 0.016630, 0.051067),\n",
    "    \"path_bbox\": (0.901061, 0.730515, 0.197877, 0.199434),\n",
    "    \"lower_line\": ((1912, 842), (1332, 1061)),\n",
    "    \"upper_line\": ((1389, 699), (1859, 666)),\n",
    "    \"similarity_threshold\": 0.6,\n",
    "    \"ip_camera_url\": \"http://192.168.0.100:8080/video\",\n",
    "    \"vehicle_classes\": [2, 3, 5, 7],  # Cars, bikes, buses, trucks\n",
    "    \"detection_conf\": 0.5\n",
    "}\n",
    "\n",
    "# ------------------ Initialization ------------------\n",
    "model = YOLO('yolov8n.pt')\n",
    "tracker = Sort()\n",
    "cap = cv2.VideoCapture(CONFIG[\"ip_camera_url\"])\n",
    "ref_hist = load_histogram(CONFIG[\"histogram_file\"])\n",
    "\n",
    "# Initialize CSV logging\n",
    "csv_file = open('violations.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Timestamp', 'ID', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "track_states = {}\n",
    "\n",
    "# ------------------ Main Loop ------------------\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 1. Check traffic signal state\n",
    "    frame_hist = calculate_histogram(frame, CONFIG[\"signal_bbox\"])\n",
    "    similarity = compare_histograms(frame_hist, ref_hist)\n",
    "    \n",
    "    # 2. Only process when signal is red\n",
    "    if similarity > CONFIG[\"similarity_threshold\"]:\n",
    "        # 3. Detect vehicles\n",
    "        results = model.predict(\n",
    "            frame, \n",
    "            classes=CONFIG[\"vehicle_classes\"], \n",
    "            conf=CONFIG[\"detection_conf\"]\n",
    "        )\n",
    "        \n",
    "        # 4. Prepare detections for tracking\n",
    "        detections = []\n",
    "        for box in results[0].boxes.data.cpu().numpy():\n",
    "            x1, y1, x2, y2, conf, cls = box\n",
    "            detections.append([x1, y1, x2, y2, conf])\n",
    "        \n",
    "        # 5. Update tracker\n",
    "        tracked_objs = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "        # 6. Check for violations\n",
    "        for obj in tracked_objs:\n",
    "            x1, y1, x2, y2, obj_id = map(float, obj)\n",
    "            obj_id = int(obj_id)\n",
    "            center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "\n",
    "            if is_within_path(center[0], center[1], CONFIG[\"path_bbox\"], frame.shape):\n",
    "                # Initialize track state\n",
    "                if obj_id not in track_states:\n",
    "                    track_states[obj_id] = {'entered': False, 'violated': False}\n",
    "\n",
    "                # Check lower line crossing\n",
    "                if not track_states[obj_id]['entered']:\n",
    "                    if point_side(center, *CONFIG[\"lower_line\"]) > 0:\n",
    "                        track_states[obj_id]['entered'] = True\n",
    "\n",
    "                # Check upper line crossing\n",
    "                if track_states[obj_id]['entered'] and not track_states[obj_id]['violated']:\n",
    "                    if point_side(center, *CONFIG[\"upper_line\"]) > 0:\n",
    "                        track_states[obj_id]['violated'] = True\n",
    "\n",
    "                # Handle violations\n",
    "                if track_states[obj_id]['violated']:\n",
    "                    # Draw violation\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"VIOLATION {obj_id}\", (int(x1), int(y1)-10),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "                    # Log to CSV\n",
    "                    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                    csv_writer.writerow([timestamp, obj_id, x1, y1, x2, y2])\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Real-Time Violation Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to access the IP camera stream.\n",
      "Stream ended or cannot read frame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tcp @ 0x3ab3eb40] Connection to tcp://10.172.250.22:4747 failed: Connection timed out\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Load reference histogram for red light detection ---\n",
    "def load_histogram(file_path):\n",
    "    \"\"\"Load a precomputed histogram from a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        histogram = pickle.load(file)\n",
    "    return histogram\n",
    "\n",
    "def calculate_histogram(image, bbox):\n",
    "    \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    x_center, y_center, box_width, box_height = bbox\n",
    "\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    roi = image[y_min:y_max, x_min:x_max]\n",
    "    histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "    return histogram\n",
    "\n",
    "def compare_histograms(hist1, hist2):\n",
    "    \"\"\"Compare two histograms using correlation; returns a similarity score.\"\"\"\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "# Arrow drawing for highlighting violations\n",
    "def draw_arrow(frame, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Draw a large, filled downward-pointing arrow above the bounding box (x1,y1,x2,y2).\n",
    "    Used to indicate a violation.\n",
    "    \"\"\"\n",
    "    center_x = (x1 + x2) // 2\n",
    "    top_y = y1 - 150  # start the arrow 150px above the vehicle's top\n",
    "    arrow_width = 50\n",
    "    arrow_height = 100\n",
    "    shaft_width = 20\n",
    "\n",
    "    # Define triangle (arrowhead) points and rectangle (shaft) points\n",
    "    arrow_tip = (center_x, y1)\n",
    "    left_corner = (center_x - arrow_width, top_y + arrow_height)\n",
    "    right_corner = (center_x + arrow_width, top_y + arrow_height)\n",
    "    shaft_top_left = (center_x - shaft_width, top_y)\n",
    "    shaft_top_right = (center_x + shaft_width, top_y)\n",
    "    shaft_bottom_left = (center_x - shaft_width, top_y + arrow_height)\n",
    "    shaft_bottom_right = (center_x + shaft_width, top_y + arrow_height)\n",
    "\n",
    "    arrow_head = np.array([arrow_tip, left_corner, right_corner], np.int32)\n",
    "    arrow_shaft = np.array([shaft_top_left, shaft_bottom_left, shaft_bottom_right, shaft_top_right], np.int32)\n",
    "    color = (0, 0, 255)  # red color for the arrow\n",
    "    cv2.fillPoly(frame, [arrow_head], color)\n",
    "    cv2.fillPoly(frame, [arrow_shaft], color)\n",
    "\n",
    "def is_within_path(cx, cy, path_bbox, frame_shape):\n",
    "    \"\"\"Check if a point (car center) lies within the specified path region (normalized coords).\"\"\"\n",
    "    height, width, _ = frame_shape\n",
    "    x_center, y_center, box_width, box_height = path_bbox\n",
    "    # Convert normalized path_bbox to pixel region\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "    return (x_min <= cx <= x_max) and (y_min <= cy <= y_max)\n",
    "\n",
    "def point_side(point, line_start, line_end):\n",
    "    \"\"\"\n",
    "    Determine which side of a directed line segment the point lies on.\n",
    "    Returns a positive value if 'point' is to the left of the line (line_start->line_end vector),\n",
    "    negative if to the right, and 0 if on the line.\n",
    "    \"\"\"\n",
    "    return ((point[0] - line_start[0]) * (line_end[1] - line_start[1]) - \n",
    "            (point[1] - line_start[1]) * (line_end[0] - line_start[0]))\n",
    "\n",
    "# --- Initialize model, tracker, and reference data ---\n",
    "model = YOLO('yolov8n.pt')  # YOLOv8 model (using the small 'n' variant for speed)\n",
    "tracker = Sort()            # Initialize SORT tracker for object tracking\n",
    "reference_histogram = load_histogram('./Histogram/modelTown_histogram.pkl')  # load the reference red-light histogram\n",
    "\n",
    "# Define the region of the frame where the traffic light appears (normalized coordinates)\n",
    "# These should be set based on calibration for the specific camera view:\n",
    "signal_bbox = (0.485879, 0.577487, 0.016630, 0.051067)   # Example normalized [x_center, y_center, width, height] for traffic light ROI\n",
    "# Define the region of interest on the road where vehicle detection is considered (path area)\n",
    "path_bbox   = (0.901061, 0.730515, 0.197877, 0.199434)   # Example normalized [x_center, y_center, width, height] for road section\n",
    "\n",
    "# Define line positions for lower (stop line) and upper (violation line) in pixel coordinates\n",
    "# These should be determined from the perspective of the camera for the specific intersection.\n",
    "\n",
    "upper_line_start = (1389, 699)\n",
    "upper_line_end = (1859, 666)\n",
    "lower_line_start = (1912, 842)\n",
    "lower_line_end = (1332, 1061)\n",
    "\n",
    "\n",
    "threshold = 0.12  # similarity threshold above which the signal is considered \"Red\"\n",
    "\n",
    "# --- Set up video capture from the mobile camera IP stream ---\n",
    "ip_camera_url = \"http://172./video\"  # replace with your phone's IP Webcam URL\n",
    "cap = cv2.VideoCapture(ip_camera_url)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to access the IP camera stream.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare video writer to save output video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps is None or fps <= 1:\n",
    "    fps = 20  # default to 20 FPS if FPS not reported by the stream\n",
    "frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "os.makedirs('./result', exist_ok=True) \n",
    "output_path = \"./result/violation_output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "track_states = {}  # Dictionary to hold tracking state (entered/violated) for each vehicle ID\n",
    "\n",
    "# --- Main loop: read frames and process ---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Stream ended or cannot read frame.\")\n",
    "        break\n",
    "\n",
    "    # 1. Draw the lane boundary lines on the frame\n",
    "    cv2.line(frame, upper_line_start, upper_line_end, (0, 255, 255), 2)  # upper line in yellow\n",
    "    cv2.line(frame, lower_line_start, lower_line_end, (255, 0, 0), 2)    # lower line in blue\n",
    "\n",
    "    # 2. Determine traffic light state using histogram comparison\n",
    "    frame_hist = calculate_histogram(frame, signal_bbox)\n",
    "    score = compare_histograms(frame_hist, reference_histogram)\n",
    "    # Draw the signal ROI box and the current similarity score\n",
    "    h, w, _ = frame.shape\n",
    "    sx, sy, sw, sh = signal_bbox\n",
    "    sx_min = int((sx - sw/2) * w); sx_max = int((sx + sw/2) * w)\n",
    "    sy_min = int((sy - sh/2) * h); sy_max = int((sy + sh/2) * h)\n",
    "    cv2.rectangle(frame, (sx_min, sy_min), (sx_max, sy_max), (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Score: {score:.2f}\", (sx_min, sy_max + 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    # (Optional) Draw the detection zone (path) bounding box on the frame for visualization\n",
    "    px, py, pw, ph = path_bbox\n",
    "    px_min = int((px - pw/2) * w); px_max = int((px + pw/2) * w)\n",
    "    py_min = int((py - ph/2) * h); py_max = int((py + ph/2) * h)\n",
    "    cv2.rectangle(frame, (px_min, py_min), (px_max, py_max), (0, 255, 0), 2)\n",
    "\n",
    "    # 3. If the signal is Red (histogram similarity above threshold), perform vehicle detection\n",
    "    if score > threshold:\n",
    "        results = model(frame)  # run YOLOv8 on the frame\n",
    "        detections = []\n",
    "        # Filter detections for cars (class id 2 for COCO, which is \"car\")\n",
    "        for det in results[0].boxes.data.cpu().numpy():\n",
    "            x1, y1, x2, y2, conf, cls_id = det[:6]\n",
    "            if int(cls_id) == 2:  # class 2 = car\n",
    "                detections.append([x1, y1, x2, y2, conf])\n",
    "        detections = np.array(detections) if len(detections) > 0 else np.empty((0, 5))\n",
    "        # Update tracker with current detections\n",
    "        tracked_objects = tracker.update(detections)\n",
    "\n",
    "        # 4. Process tracked vehicles for violation logic\n",
    "        for x1, y1, x2, y2, track_id in tracked_objects:\n",
    "            track_id = int(track_id)\n",
    "            # Compute the center of the bounding box\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "\n",
    "            # Only consider vehicles within the defined path/road area\n",
    "            if not is_within_path(center_x, center_y, path_bbox, frame.shape):\n",
    "                continue\n",
    "\n",
    "            # Update tracking state: check if vehicle has entered and then crossed the lines\n",
    "            if track_id not in track_states:\n",
    "                # If the vehicle has passed the **lower (stop) line**, mark it as \"entered\"\n",
    "                if point_side((center_x, center_y), lower_line_start, lower_line_end) > 0:\n",
    "                    track_states[track_id] = {\"entered\": True, \"violated\": False}\n",
    "            else:\n",
    "                # If already entered and now passes the **upper line**, mark as a violation\n",
    "                if (track_states[track_id][\"entered\"] and not track_states[track_id][\"violated\"] and \n",
    "                        point_side((center_x, center_y), upper_line_start, upper_line_end) > 0):\n",
    "                    track_states[track_id][\"violated\"] = True\n",
    "\n",
    "            # Determine if this vehicle is in violation\n",
    "            violated = track_states.get(track_id, {}).get(\"violated\", False)\n",
    "            # Draw the vehicle's bounding box (red if violated, green if not yet violated)\n",
    "            color = (0, 0, 255) if violated else (0, 255, 0)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            # If violation occurred, draw the downward arrow indicator\n",
    "            if violated:\n",
    "                draw_arrow(frame, int(x1), int(y1), int(x2), int(y2))\n",
    "                # (Optional: could log or save violation event details here)\n",
    "\n",
    "        # Write this frame to the output video (only recording during red signal periods)\n",
    "        video_writer.write(frame)\n",
    "    else:\n",
    "        # If the light is not red, we do not perform detection or tracking (for efficiency),\n",
    "        # and we skip writing the frame to the output video.\n",
    "        pass\n",
    "\n",
    "    # 5. Display the frame with annotations in a window\n",
    "    cv2.imshow(\"Red Light Violation Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
